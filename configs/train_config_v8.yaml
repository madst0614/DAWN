# DAWN v8.0 Training Config
# SharedNeurons + NeuronMemory (FFN replacement)

# Data
data:
  base_dir: /content/drive/MyDrive/data
  train_file: train/wikitext_5to1_texts.pkl
  val_file: validation/wikitext_5to1_texts.pkl

# Model Architecture (v8.0: SharedNeurons + NeuronMemory)
model:
  model_version: "8.0"    # DAWN v8.0 - SharedNeurons + NeuronMemory
  d_model: 256            # Hidden dimension
  n_layers: 4             # Number of transformer layers
  n_heads: 4              # Number of attention heads

  # TransformNeurons parameters (shared across layers)
  rank: 64                # Projection rank (4 heads x 16 d_head)
  n_input: 8              # Number of input neurons (256 -> 64 compression)
  n_process: 32           # Number of Householder process neurons
  n_output: 8             # Number of output neurons (64 -> 256 restoration)
  process_k: 3            # Number of process neurons to select (top-k)

  # KnowledgeNeurons parameters (shared across layers, replaces FFN)
  n_knowledge: 64         # Number of knowledge neurons
  knowledge_k: 8          # Number of knowledge neurons to retrieve (top-k)

  # Architecture
  max_seq_len: 128        # Maximum sequence length
  dropout: 0.1            # Dropout rate

# Training
training:
  batch_size: 128         # Batch size
  num_epochs: 30          # Total epochs
  lr: 0.0003              # Learning rate
  weight_decay: 0.1       # Weight decay for regularization
  warmup_epochs: 2        # Warmup epochs

  # Regularization (v8.0: orthogonality + process norm + knowledge diversity)
  orthogonality_weight: 0.01   # Input/Output neuron orthogonality loss
  process_norm_weight: 0.01    # Process neuron norm regularization (||v|| = 1)
  load_balance_weight: 0.01    # Load balance loss for routing

# Mixed precision (faster training on GPU)
use_amp: true

# Paths
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints_v8
log_dir: /content/drive/MyDrive/dawn/checkpoints_v8

# Notes:
# v8.0 Key Changes from v7.9:
# - SharedNeurons: All layers share same neuron pool
#   - TransformNeurons: input/process/output neurons (same as v7.9)
#   - KnowledgeNeurons: K/V neurons for memory retrieval (NEW)
# - NeuronMemory: Replaces FFN with inner-product based knowledge retrieval
#   - Query projection (W_Q): d_model -> rank
#   - Knowledge search: Q @ K.T / sqrt(rank) -> top-k retrieval
#   - Weighted sum of V values
# - Auxiliary losses:
#   - orth_total: Input/Output neuron orthogonality
#   - process_norm: Process neuron ||v|| = 1
#   - knowledge_div: Knowledge K diversity (NEW)
#
# Parameter count:
#   SharedNeurons (shared):
#     - InputNeuron: 8 x 256 x 64 = 131K
#     - ProcessNeuron: 32 x 64 = 2K
#     - OutputNeuron: 8 x 64 x 256 = 131K
#     - KnowledgeK: 64 x 64 = 4K
#     - KnowledgeV: 64 x 256 = 16K
#   Per-layer (routers + W_Q):
#     - Compressor routers: 3 x (256x8 + 64x32) x 4 layers
#     - Expander router: (64x32 + 64x8) x 4 layers
#     - NeuronMemory W_Q: 256x64 x 4 layers
