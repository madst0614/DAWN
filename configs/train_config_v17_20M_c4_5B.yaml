# DAWN v17 Training Config - 20M Scale, 5B tokens
# Unified Neuron Architecture: Attention + Knowledge both use Feature-Restore pattern

data:
  base_dir: /content/drive/MyDrive/data
  train_files:
    - train/c4/c4_raw_000.pt
    - train/c4/c4_raw_001.pt
    - train/c4/c4_raw_002.pt
    - train/c4/c4_raw_003.pt
    - train/c4/c4_raw_004.pt
    - train/c4/c4_raw_005.pt
    - train/c4/c4_raw_006.pt
    - train/c4/c4_raw_007.pt
    - train/c4/c4_raw_008.pt
    - train/c4/c4_raw_009.pt
  val_files:
    - val/c4/c4_val_50M.pt
  max_train_tokens: 5000000000
  max_val_tokens: 2000000

model:
  model_version: "17"
  d_model: 384
  n_layers: 12
  n_heads: 6
  rank: 64
  state_dim: 64

  # Attention (same as v16.4)
  n_feature_qk: 96
  top_k_feature_qk: 8
  n_feature_v: 24
  top_k_feature_v: 3
  n_restore_qk: 96
  top_k_restore_qk: 8
  n_restore_v: 24
  top_k_restore_v: 3

  # Knowledge (NEW: Feature-Restore pattern)
  n_knowledge: 24
  knowledge_rank: 128
  top_k_knowledge: 4

  max_seq_len: 512
  dropout: 0.1
  gradient_checkpointing: false
  d_space: 64
  router_dropout: 0.1
  token_routing: false
  use_ssm_context: true

  # Excitability
  excitability_tau: 1.5
  excitability_ema_alpha: 0.01
  excitability_decay_rate: 0.99995

training:
  batch_size: 96
  num_epochs: 1
  lr: 0.00055
  weight_decay: 0.1
  warmup_ratio: 0.06
  orthogonality_weight: 0.01
  diversity_weight: 0.1
  load_balance_weight: 0.0
  entropy_weight: 0.0
  process_norm_weight: 0.0

use_amp: true
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints_v17_20M_c4_5B
log_dir: /content/drive/MyDrive/dawn/logs_v17_20M_c4_5B

# v17 Architecture (Unified Neuron Architecture)
#   Attention Circuit:
#   - Feature_QK=96 (k=8) - Q/K shared pool, separate routing
#   - Feature_V=24 (k=3)
#   - Restore_QK=96 (k=8) - Q/K shared pool, separate routing
#   - Restore_V=24 (k=3)
#
#   Knowledge Circuit (NEW: Feature-Restore pattern):
#   - Knowledge=24 neurons (k=4) - Feature-Restore pattern
#   - Feature_Know: [24, 384, 128] - information extraction
#   - Restore_Know: [24, 128, 384] - knowledge restoration
#
#   Both circuits use same Feature-Restore pattern:
#   - Attention: x -> Feature -> h -> Restore -> Q/K/V -> attention
#   - Knowledge: x -> Feature_Know -> h -> Restore_Know -> knowledge output
