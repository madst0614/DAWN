# DAWN Training Configuration
# Dynamic Neuron Transformer Architecture

# Data
data:
  base_dir: /content/drive/MyDrive/data
  train_file: train/wikitext_5to1_texts.pkl
  val_file: validation/wikitext_5to1_texts.pkl

# Model Architecture (v6.0: Orthogonal Basis FFN)
model:
  model_version: "6.0"    # DAWN model version
  d_model: 256            # Hidden dimension
  n_layers: 4             # Number of transformer layers
  n_heads: 4              # Number of attention heads

  # Neurons (v6.0: Free coordinates in basis space)
  n_neurons: 256          # Size of neuron pool per layer (512 → 256, 더 효율적)
  neuron_k: 16            # Top-k neurons to select
  router_temperature: 2.0 # Router softmax temperature (higher = smoother distribution)

  # Basis FFN (v6.0: Orthogonal Basis with token-level FFN)
  n_basis: 8              # Number of orthogonal basis (16 → 8, 명확한 역할)
  basis_rank: 64          # Basis rank (32 → 64, 더 강력한 표현력)
  # v6.0 변경: Token residual network 제거, Token별 동적 FFN으로 대체

  # Architecture
  d_ff: 512               # Feed-forward dimension (2x d_model)
  max_seq_len: 128        # Maximum sequence length
  dropout: 0.1            # Dropout rate

# Training
training:
  batch_size: 128         # Batch size
  num_epochs: 30          # Total epochs
  lr: 0.0003              # Learning rate
  weight_decay: 0.1       # Weight decay for regularization
  warmup_epochs: 2        # Warmup epochs

  # v6.0: Simplified regularization (only orthogonality)
  orthogonality_weight: 0.1     # Basis orthogonality regularization (λ=0.1)
  # v6.0 removed: basis_sparsity, basis_diversity (자연스러운 neuron clustering 허용)

# Mixed precision (faster training on GPU)
use_amp: true

# Paths
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints
log_dir: /content/drive/MyDrive/dawn/checkpoints
