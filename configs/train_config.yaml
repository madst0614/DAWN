# DAWN Training Configuration
# New simplified architecture with InputNeurons and ProcessNeurons

# Data
data:
  base_dir: /content/drive/MyDrive/data
  train_file: train/wikitext_5to1_texts.pkl
  val_file: validation/wikitext_5to1_texts.pkl

# Model Architecture
model:
  d_model: 512            # Hidden dimension
  n_layers: 6             # Number of DAWN layers
  n_input: 64             # InputNeurons per layer (pattern-based activation)
  n_process: 128          # ProcessNeurons per layer (context aggregation)
  max_seq_len: 128        # Maximum sequence length
  dropout: 0.1            # Dropout rate

# Training
training:
  batch_size: 128         # Batch size
  num_epochs: 30          # Total epochs
  lr: 0.0003              # Learning rate (increased for faster convergence)
  weight_decay: 0.1       # Weight decay for regularization
  warmup_epochs: 2        # Warmup epochs

# Mixed precision (faster training on GPU)
use_amp: true

# Paths
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints
log_dir: /content/drive/MyDrive/dawn/checkpoints
