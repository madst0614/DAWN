# DAWN v10.1 Training Config
# Top-K Sparse Compress/Expand Architecture
# v10.0과 동일한 파라미터로 비교용 설정

# Data
data:
  base_dir: /content/drive/MyDrive/data
  train_files:
    - train/wikitext_5to1_texts.pkl
  val_files:
    - validation/wikitext_5to1_texts.pkl

# Model Architecture (v10.1 - v10.0과 동일 파라미터)
model:
  model_version: "10.1"
  d_model: 320
  n_layers: 4
  n_heads: 4
  rank: 64

  # CompressNeurons / ExpandNeurons (v10.0과 동일)
  n_compress: 48          # Q/K/V/M 공유
  n_expand: 12            # O 공유 (4:1 비율)

  # Top-K Selection (v10.1 핵심)
  compress_top_k: 8       # 48개 중 8개만 선택 (16.7%)
  expand_top_k: 4         # 12개 중 4개만 선택 (33.3%)
  router_noise: 0.1       # 학습 시 탐색용 noise

  # KnowledgeNeurons
  n_knowledge: 80
  knowledge_k: 10

  # Architecture
  max_seq_len: 128
  dropout: 0.1

# Training (v10.0과 동일)
training:
  batch_size: 128
  num_epochs: 30
  lr: 0.0003
  weight_decay: 0.1
  warmup_ratio: 0.05

  # Regularization
  orthogonality_weight: 0.01    # compress/expand 직교성
  diversity_weight: 0.1         # knowledge diversity
  load_balance_weight: 0.01     # routing 균등 분포
  process_norm_weight: 0.0      # v10 미지원 (process neurons 없음)

use_amp: true
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints_v10_1
log_dir: /content/drive/MyDrive/dawn/logs_v10_1

# =============================================================================
# v10.0 vs v10.1 비교 (동일 파라미터)
# =============================================================================
#
# | 항목              | v10.0 (soft)      | v10.1 (top-k)        |
# |-------------------|-------------------|----------------------|
# | n_compress        | 48                | 48                   |
# | n_expand          | 12                | 12                   |
# | Compressor 연산   | 48개 전부          | 8개만 (top-k)        |
# | Expander 연산     | 12개 전부          | 4개만 (top-k)        |
# | 메모리            | 더 많음            | 절약 (~3x)           |
# | 속도              | 기준               | 더 빠름 (~2-3x)      |
#
# =============================================================================
# 파라미터 계산 (v10.0과 동일):
# =============================================================================
#   compress: 48 × 320 × 64 = 983,040 (0.98M)
#   expand: 12 × 64 × 320 = 245,760 (0.25M)
#   knowledge: 80×64 + 80×320 = 30,720 (31K)
#   SharedNeurons 총: ~1.26M
#
#   embeddings: 30522 × 320 = 9.77M
#   pos_emb: 128 × 320 = 41K
#   routers: ~300K
#   layernorms: ~10K
#
#   Total: ~11.4M (v10.0과 동일)
#
# =============================================================================
# 비교 실험 방법:
# =============================================================================
# 1. v10.0으로 학습: python train.py --config train_config_v10.yaml
# 2. v10.1로 학습: python train.py --config train_config_v10_1.yaml
# 3. 동일 epoch에서 val_loss, 속도, 메모리 비교
#
# 기대 결과:
# - v10.1이 같은 파라미터로 더 빠르게 학습
# - top-k sparse selection으로 메모리 효율 증가
# - 성능은 비슷하거나 약간 낮을 수 있음 (sparse routing의 trade-off)
# =============================================================================
