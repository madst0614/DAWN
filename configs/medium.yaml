# DAWN v8 Medium (~18-20M params)
# Balanced performance for serious training

model:
  model_version: "8.0"
  vocab_size: 30522
  d_model: 512
  n_layers: 12
  n_heads: 4
  rank: 64
  max_seq_len: 256
  n_input: 8
  n_process: 32
  n_output: 8
  process_k: 4
  n_knowledge: 128
  knowledge_k: 12
  dropout: 0.1

data:
  base_dir: /content/drive/MyDrive/data
  train_files:
    - train/c4_5to1_texts.pkl
    - train/openwebtext_5to1_texts.pkl
    - train/wikitext_5to1_texts.pkl
  val_files:
    - validation/c4_5to1_texts.pkl
    - validation/openwebtext_5to1_texts.pkl
    - validation/wikitext_5to1_texts.pkl

training:
  batch_size: 64
  num_epochs: 3
  lr: 0.0002
  warmup_ratio: 0.1
  weight_decay: 0.01
  orthogonality_weight: 0.01
  load_balance_weight: 0.01

use_amp: true
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints_v83
log_dir: /content/drive/MyDrive/dawn/checkpoints_v83
