# DAWN v13.1 Training Config - 12M Scale, 500M tokens
# Separate QK/V Expand Pools
# Based on train_config_11M_c4_500M.yaml

# Data
data:
  base_dir: /content/drive/MyDrive/data
  train_files:
    - train/c4/c4_raw_000.pt
    - train/c4/c4_raw_001.pt
  val_files:
    - val/c4/c4_val_50M.pt
  max_train_tokens: 500000000   # 500M tokens
  max_val_tokens: 2000000        # 2M tokens

# Model Architecture
model:
  model_version: "13.1"
  d_model: 320
  n_layers: 4
  n_heads: 4
  rank: 64
  state_dim: 64
  n_compress: 48
  n_expand_QK: 12    # Q/K shared pool
  n_expand_V: 12     # V separate pool
  n_knowledge: 80
  knowledge_k: 10
  knowledge_rank: 64
  max_seq_len: 512
  dropout: 0.1
  gradient_checkpointing: false
  top_k_compress: 12
  top_k_QK: 4        # Top-k for QK router
  top_k_V: 6         # Top-k for V router (can be different)
  router_dropout: 0.1
  token_routing: false

# Training
training:
  batch_size: 256
  num_epochs: 10
  lr: 0.0004
  weight_decay: 0.1
  warmup_ratio: 0.06
  orthogonality_weight: 0.01
  diversity_weight: 0.1
  load_balance_weight: 0.03  # Lower than 0.05
  entropy_weight: 0.0
  process_norm_weight: 0.0

use_amp: true
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints_v13_1_12M_c4_500M
log_dir: /content/drive/MyDrive/dawn/logs_v13_1_12M_c4_500M

# v13.1 Changes:
#   - expand_neurons_pool â†’ expand_neurons_QK + expand_neurons_V
#   - Q/K share same weights (attention similarity)
#   - V has separate specialization (value retrieval)
#   - Total params unchanged: 12+12 = 24 neurons
