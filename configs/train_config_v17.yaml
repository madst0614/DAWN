# DAWN v17 Training Config
# Full Vector Neurons + Soft/Hard Selection
# Training: soft selection (all neurons via softmax, gradient flow)
# Inference: top-k hard selection (sparse, efficient)

# Data
data:
  base_dir: /content/drive/MyDrive/data
  train_files:
    - train/wikitext_5to1_texts.pkl
  val_files:
    - val/wikitext_5to1_texts.pkl

# Model Architecture
model:
  model_version: "17.0"
  d_model: 320
  n_layers: 4
  n_heads: 4
  state_dim: 64

  # Vector neurons (NO rank matrices - all neurons are [n, d_model])
  n_feature: 768              # Shared pool for QK/V (separate routing)
  n_relational: 256           # Shared pool for Q/K (separate routing)
  n_value: 128                # V expansion neurons

  # Top-k for inference only (training uses soft selection over all)
  top_k_feature: 64           # inference only
  top_k_relational: 64        # inference only
  top_k_value: 32             # inference only

  # Knowledge neurons
  n_knowledge: 80
  coarse_k: 20
  fine_k: 10
  knowledge_rank: 128

  max_seq_len: 128
  dropout: 0.1

  # Router settings
  d_space: 64
  router_dropout: 0.1
  temperature: 1.0            # soft selection sharpness
  use_ssm_context: true
  gradient_checkpointing: false

# Training
training:
  batch_size: 128
  num_epochs: 30
  lr: 0.0003
  weight_decay: 0.1
  warmup_epochs: 2

  # Regularization
  diversity_weight: 0.1
  load_balance_weight: 0.03   # aux_loss coefficient
  entropy_weight: 0.0
  process_norm_weight: 0.0

use_amp: true
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints_v17
log_dir: /content/drive/MyDrive/dawn/logs_v17

# v17 Changes from v16:
#   - ALL neurons are vectors [n, d_model] (no rank matrices)
#   - Training: soft selection (all neurons via softmax)
#   - Inference: top-k hard selection (sparse)
#   - Temperature parameter for softmax sharpness
#   - Shared pools: Feature (QK/V), Relational (Q/K)
#   - top_k values only used during inference
