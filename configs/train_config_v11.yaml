# DAWN v11.0 Training Config
# Hard Top-K Routing: 선택된 k개 뉴런만 계산 (연산량 대폭 절감)
# v10 대비 변경: Soft routing → Hard Top-K selection

# Data
data:
  base_dir: /content/drive/MyDrive/data
  train_files:
    - train/wikitext_5to1_texts.pkl
  val_files:
    - val/wikitext_5to1_texts.pkl

# Model Architecture
model:
  model_version: "11.0"  # Hard Top-K Routing!
  d_model: 320
  n_layers: 4
  n_heads: 4
  rank: 64

  # Neurons (v10과 동일한 구조)
  n_compress: 48
  n_expand: 12

  # Hard Top-K Selection (v11 핵심!)
  compress_top_k: 2       # 48개 중 2개 선택 → 24배 절약
  expand_top_k: 2         # 12개 중 2개 선택 → 6배 절약

  n_knowledge: 80
  knowledge_k: 10
  knowledge_rank: 64
  max_seq_len: 128
  dropout: 0.1

# Training
training:
  batch_size: 128
  num_epochs: 30
  lr: 0.0003
  weight_decay: 0.1
  warmup_epochs: 2

  # Regularization
  orthogonality_weight: 0.01
  diversity_weight: 0.1
  load_balance_weight: 0.01   # top-k에서 중요 (균등 분배)
  process_norm_weight: 0.0

use_amp: true
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints_v11
log_dir: /content/drive/MyDrive/dawn/logs_v11

# =============================================================================
# v10 vs v11 비교 (Hard Top-K의 효과)
# =============================================================================
#
# | 항목              | v10.0 (Soft)      | v11.0 (Hard Top-K)  |
# |-------------------|-------------------|---------------------|
# | Routing           | 48개 전부 softmax | 2개만 선택          |
# | Compress 연산     | 48회 projection   | 2회 projection      |
# | Expand 연산       | 12회 projection   | 2회 projection      |
# | 연산량 절약       | -                 | ~24x (compress)     |
# | 파라미터          | 동일              | 동일                |
# | Sparsity          | Dense (100%)      | Sparse (4.2%)       |
#
# Hard Top-K 장점:
# 1. 연산량 대폭 절감 (MoE처럼 sparse activation)
# 2. 뉴런별 특화 학습 유도 (expert specialization)
# 3. 추론 속도 향상
#
# =============================================================================
