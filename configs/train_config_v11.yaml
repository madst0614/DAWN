# DAWN v11.0 Training Config
# Unified Compression: 1 compressor + expand_Q/K/V
# Attention in d_model space (not rank space)

# Data
data:
  base_dir: /content/drive/MyDrive/data
  train_files:
    - train/wikitext_5to1_texts.pkl
  val_files:
    - val/wikitext_5to1_texts.pkl

# Model Architecture
model:
  model_version: "11.0"
  d_model: 320
  n_layers: 4
  n_heads: 4
  rank: 64

  # Neurons (v10과 동일)
  n_compress: 48
  n_expand: 48

  n_knowledge: 80
  knowledge_k: 10
  knowledge_rank: 64
  max_seq_len: 128
  dropout: 0.1

# Training
training:
  batch_size: 128
  num_epochs: 30
  lr: 0.0003
  weight_decay: 0.1
  warmup_epochs: 2

  # Regularization
  orthogonality_weight: 0.01
  diversity_weight: 0.1
  load_balance_weight: 0.01
  process_norm_weight: 0.0

use_amp: true
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints_v11
log_dir: /content/drive/MyDrive/dawn/logs_v11

# =============================================================================
# v10 vs v11 비교 (Unified Compression)
# =============================================================================
#
# | 항목              | v10.0              | v11.0                  |
# |-------------------|--------------------|-----------------------|
# | Compressors       | 3개 (Q/K/V 별도)   | 1개 (unified)          |
# | Q/K/V 생성        | 각각 compress_neurons| expand_Q/K/V Linear   |
# | Attention space   | rank               | d_model               |
# | d_head            | rank // n_heads    | d_model // n_heads    |
# | Routing 연산      | 3회/layer          | 1회/layer (Attn)      |
#
# v11 이점:
# 1. 라우팅 연산 3배 감소 (Attention 부분)
# 2. d_model에서 Attention → 더 풍부한 표현력
# 3. 단일 압축 표현에서 Q/K/V 분화 → 정보 효율성
#
# =============================================================================
