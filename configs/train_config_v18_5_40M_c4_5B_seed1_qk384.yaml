# DAWN v18.5 Training Config - 40M Scale, 5B tokens (Seed 1, QK-384)
# v18.5: Context-Aware Restore Routing
# - Feature routing: done on input x (same as v18.4)
# - Restore routing: done on [neuron_context, h] (no h projection)
# - neuron_context: weighted sum of feature neuron embeddings (d_space)
# - h: raw intermediate representation (rank for attn, knowledge_rank for know)

seed: 1

data:
  base_dir: /content/drive/MyDrive/data
  train_files:
    - train/c4/c4_raw_000.pt
    - train/c4/c4_raw_001.pt
    - train/c4/c4_raw_002.pt
    - train/c4/c4_raw_003.pt
    - train/c4/c4_raw_004.pt
    - train/c4/c4_raw_005.pt
    - train/c4/c4_raw_006.pt
    - train/c4/c4_raw_007.pt
    - train/c4/c4_raw_008.pt
    - train/c4/c4_raw_009.pt
  val_files:
    - val/c4/c4_val_50M.pt
  max_train_tokens: 5000000000
  max_val_tokens: 2000000

model:
  model_version: "18.5"
  d_model: 384
  n_layers: 12
  n_heads: 6
  rank: 16
  state_dim: 64

  # Attention neurons
  n_feature_qk: 470
  n_feature_v: 1060
  n_restore_qk: 240
  n_restore_v: 520

  # Knowledge neurons
  n_feature_know: 970
  n_restore_know: 690
  knowledge_rank: 16

  max_seq_len: 512
  dropout: 0.1
  gradient_checkpointing: true
  d_space: 256
  router_dropout: 0.1
  attention_token_routing: true
  knowledge_token_routing: true
  use_ssm_context: false

  # v18.5 specific - context-aware restore routing
  max_paths: 2
  path_max_k: 16
  learnable_tau: true
  tau_reg_weight: 0.01

training:
  batch_size: 128
  gradient_accumulation_steps: 1
  num_epochs: 1
  lr: 0.00065
  weight_decay: 0.1
  warmup_ratio: 0.06
  orthogonality_weight: 0.01
  diversity_weight: 0.1
  load_balance_weight: 0.001
  tau_reg_weight: 0.01

use_amp: true
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints_v18.5_40M_c4_5B_seed1_qk384
log_dir: /content/drive/MyDrive/dawn/logs_v18.5_40M_c4_5B_seed1_qk384

# v18.5 Context-Aware Restore Routing Architecture
#
#   Key difference from v18.4:
#   - Feature routing: same as v18.4 (on input x)
#   - Restore routing: context-aware (on [neuron_context, h])
#     - No h projection - uses raw h directly
#     - Context dim: d_space + rank (attn) or d_space + knowledge_rank (know)
#     - neuron_context: einsum('bsn,nd->bsd', feature_weights, feature_emb)
#
#   Benefits:
#   - Restore routing sees feature processing results
#   - More informed neuron selection for restoration
#   - Q/K fully separated: separate projections, norms, tau
#   - tau_proj_feature (4 pools) for feature routing
#   - tau_proj_restore_Q/K/v/know for context-based restore routing
#
#   Attention Circuit (2-path routing):
#   - Feature_QK=470 (2 paths x 16): per-token Q/K compression - tau on x
#   - Feature_V=1060 (2 paths x 16): per-token V compression - tau on x
#   - Restore_QK=240 (2 paths x 16): context-aware restoration
#   - Restore_V=520 (2 paths x 16): context-aware restoration
#
#   Knowledge Circuit (2-path routing):
#   - Feature_Know=970 (2 paths x 16): per-token compression - tau on x
#   - Restore_Know=690 (2 paths x 16): context-aware restoration
