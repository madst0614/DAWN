# DAWN v18.5 Training Config - 40M Scale, 5B tokens (Seed 1, QK-384)
# v18.5: Context-Aware Restore Routing
# - Feature routing: done on input x (same as v18.4)
# - Restore routing: done on [h_proj, neuron_context]
# - h_proj: intermediate representation h projected to d_space
# - neuron_context: weighted sum of feature neuron embeddings

seed: 1

data:
  base_dir: /content/drive/MyDrive/data
  train_files:
    - train/c4/c4_raw_000.pt
    - train/c4/c4_raw_001.pt
    - train/c4/c4_raw_002.pt
    - train/c4/c4_raw_003.pt
    - train/c4/c4_raw_004.pt
    - train/c4/c4_raw_005.pt
    - train/c4/c4_raw_006.pt
    - train/c4/c4_raw_007.pt
    - train/c4/c4_raw_008.pt
    - train/c4/c4_raw_009.pt
  val_files:
    - val/c4/c4_val_50M.pt
  max_train_tokens: 5000000000
  max_val_tokens: 2000000

model:
  model_version: "18.5"
  d_model: 384
  n_layers: 12
  n_heads: 6
  rank: 16
  state_dim: 64

  # Attention - 4x neurons from v17.1
  n_feature_qk: 384
  n_feature_v: 1000
  n_restore_qk: 384
  n_restore_v: 1000

  # Knowledge - 4x neurons from v17.1
  n_feature_know: 580
  n_restore_know: 580
  knowledge_rank: 16

  max_seq_len: 512
  dropout: 0.1
  gradient_checkpointing: true
  d_space: 256
  router_dropout: 0.1
  attention_token_routing: true
  knowledge_token_routing: true
  use_ssm_context: false

  # v18.5 specific - context-aware restore routing
  max_paths: 2
  path_max_k: 16
  learnable_tau: true
  tau_reg_weight: 0.01

training:
  batch_size: 128
  gradient_accumulation_steps: 1
  num_epochs: 1
  lr: 0.00065
  weight_decay: 0.1
  warmup_ratio: 0.06
  orthogonality_weight: 0.01
  diversity_weight: 0.1
  load_balance_weight: 0.0001
  tau_reg_weight: 0.01

use_amp: true
checkpoint_dir: /content/drive/MyDrive/dawn/checkpoints_v18.5_40M_c4_5B_seed1_qk384
log_dir: /content/drive/MyDrive/dawn/logs_v18.5_40M_c4_5B_seed1_qk384

# v18.5 Context-Aware Restore Routing Architecture
#
#   Key difference from v18.4:
#   - Feature routing: same as v18.4 (on input x)
#   - Restore routing: context-aware (on [h_proj, neuron_context])
#     - h_proj: h projected to d_space via Linear
#     - neuron_context: einsum('pbsn,nd->pbsd', feature_weights, feature_emb)
#
#   Benefits:
#   - Restore routing sees feature processing results
#   - More informed neuron selection for restoration
#   - tau_proj_feature (4 pools) instead of tau_proj (8 pools)
#   - Restore tau computed from context scores (mean-based)
#
#   Attention Circuit (2-path routing):
#   - Feature_QK=384 (2 paths x 16): per-token Q/K compression - tau on x
#   - Feature_V=1000 (2 paths x 16): per-token V compression - tau on x
#   - Restore_QK=384 (2 paths x 16): context-aware restoration
#   - Restore_V=1000 (2 paths x 16): context-aware restoration
#
#   Knowledge Circuit (2-path routing):
#   - Feature_Know=580 (2 paths x 16): per-token compression - tau on x
#   - Restore_Know=580 (2 paths x 16): context-aware restoration
